<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Speech Language and Music Lab</title> <meta name="author" content="Hsin-Min Wang"/> <meta name="description" content=""/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://slam.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/members/">Members</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Speech Language and Music Lab </h1> <p class="desc"></p> </header> <article> <div class="clearfix"> <div class="col-sm mt-3 mt-md-0" style="display:table-cell; vertical-align:middle; text-align:center"> <a href="https://sinica-slam.github.io/" target="_blank" rel="noopener noreferrer"> <img class="img-fluid rounded z-depth-1" src="/assets/img/slam_members_2022.08.jpg"> </a> <div class="caption"> Our current lab members and summer interns, 2022.08.31 </div> </div> <div style="text-align:justify"> Our research interests include speech processing, natural language processing, multimedia information retrieval, machine learning, and pattern recognition. Our research goal is to develop methods for analyzing, extracting, recognizing, indexing, and retrieving information from audio data, with special emphasis on speech and music. </div> <div style="text-align:justify"> In the field of speech, research has been focused mainly on speaker recognition, spoken language recognition, voice conversion, and spoken document retrieval/summarization. Our recent achievements include locally linear embedding-based approaches for voice conversion and post-filtering, discriminative autoencoders for speech/speaker recognition, and novel paragraph embedding methods for spoken document retrieval/summarization. Our ongoing research includes audio-visual speaker recognition and speech enhancement, subspace neural networks for spoken language/dialect/accent recognition, many-to-one/non-parallel voice conversion, and neural network-based spoken document retrieval/summarization and question answering.</div> <div style="text-align:justify"> In the music field, research has been focused mainly on vocal melody extraction and automatic generation of music video. Our recent achievements in this field include an acoustic-phonetic F0 modeling framework for vocal melody extraction and an emotion-oriented pseudo song prediction and matching framework for automatic music video generation. We have successfully implemented a complete automatic music video generation system that can automatically edit a long user-generated video into a music-compliant short professional-like video. Our ongoing research includes continuous improvement of our own technologies and systems, cover song identification, and automatic generation of set list for concert video, so as to facilitate the management and retrieval of a large music database. Future research directions also include singing voice synthesis, speech to singing voice conversion, and music structure analysis/summarization.</div> </div> <div class="news"> <h2>news</h2> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Jun 1, 2021</th> <td> Congratulations to Yao-Fei Cheng and Fan-Lin Wang for receiving the Travel Grant of ISCA Interspeech2021. </td> </tr> <tr> <th scope="row">Jun 1, 2020</th> <td> Congratulations to Shang-Yi Chuang for receiving the Travel Grant of ISCA Interspeech2020. </td> </tr> </table> </div> </div> <div class="publications"> <h2>selected publications</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ASR</abbr> <abbr class="badge badge-info">Interspeech</abbr> </div> <div id="HS22_interspeech" class="col-sm-8"> <div class="title">Chain-based Discriminative Autoencoders for Speech Recognition</div> <div class="author"> Hung-Shin Lee, Pin-Tuan Huang, Yao-Fei Cheng, and <em>Hsin-Min Wang</em> </div> <div class="periodical"> <em>In Proc. Interspeech</em> 2022 </div> <div class="links"> <a href="http://arxiv.org/abs/2203.13687" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">VC</abbr> <abbr class="badge badge-info">ASRU</abbr> </div> <div id="seq2seq-evlc" class="col-sm-8"> <div class="title">Mandarin Electrolaryngeal Speech Voice Conversion with Sequence-to-Sequence Modeling</div> <div class="author"> Ming-Chi Yen, Wen-Chin Huang, Kazuhiro Kobayashi, Yu-Huai Peng, Shu-Wei Tsai, <a href="https://www.citi.sinica.edu.tw/pages/yu.tsao/index_en.html" target="_blank" rel="noopener noreferrer">Yu Tsao</a>, Tomoki Toda, Jang Jyh-Shing Roger, and <em>Hsin-Min Wang</em> </div> <div class="periodical"> <em>In 2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</em> 2021 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ST</abbr> <abbr class="badge badge-info">Interspeech</abbr> </div> <div id="cheng21_interspeech" class="col-sm-8"> <div class="title">AlloST: Low-Resource Speech Translation Without Source Transcription</div> <div class="author"> Yao-Fei Cheng, Hung-Shin Lee, and <em>Hsin-Min Wang</em> </div> <div class="periodical"> <em>In Proc. Interspeech</em> 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2105.00171" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a href="https://github.com/jamfly/AlloST" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="/feed.xml" title="RSS Feed"><i class="fas fa-rss-square"></i></a> </div> <div class="contact-note"> You can even add a little note about which of these is the best way to reach you. </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2022 Hsin-Min Wang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>